# -*- coding:utf-8 -*-
# vim:et:ts=4:sw=4:
#!/usr/bin/env python

######################################################################
__author__  = 'shumlab@foxmail.com'
__create__  = '2022-12-07'
__file__    = 'ExportDocMD2Hugo.py'
__license__ = '2022 All rights reserved.'
__doc__     = 'å¯¼å‡ºè¯­é›€çš„å•ç¯‡æ–‡æ¡£, å¹¶æ ¹æ®éœ€è¦è½¬æ¢æˆ Hugo æ ¼å¼åšæ–‡, åŠé€šè¿‡é•œåƒå›æºçš„æ–¹å¼å¤„ç†å¯¹åº”çš„å›¾ç‰‡.'
#####################################################################
import requests, optparse, re
from bs4 import BeautifulSoup

def __main__():
    usage = "usage: python3 %prog [options] \n\nExample:\n"
    usage = usage + "    python3 %prog -u https://www.yuque.com/shenweiyan/cookbook/try-yuque-api -t 'è¯­é›€;Python' -s cos.shenlab.cn -o"
    usage = usage + "\n\nDescription:\n"
    usage = usage + "    1. å¯¼å‡ºè¯­é›€çš„å•ç¯‡æ–‡æ¡£, å¹¶æ ¹æ®éœ€è¦è½¬æ¢æˆ Hugo æ ¼å¼åšæ–‡, åŠé€šè¿‡é•œåƒå›æºçš„æ–¹å¼å¤„ç†å¯¹åº”çš„å›¾ç‰‡ã€‚\n"
    usage = usage + "    2. -u ä¸èƒ½ä¸ºç©ºã€‚\n"
    usage = usage + "    3. -o è‡ªåŠ¨ä¿å­˜ä¸º create_at-slug.md æ ¼å¼çš„æ–‡ä»¶, å¦‚ 2022-12-08-try-yuque-api.md ã€‚"
    parser = optparse.OptionParser(usage=usage)
    parser.add_option("-u", "--url", dest="url", help="æ–‡ç« çš„ URL è®¿é—®åœ°å€")
    parser.add_option("-s", "--site", dest="site", default="cos.shenlab.cn", help="é•œåƒå›æºçš„ URL åœ°å€ (é»˜è®¤: cos.shenlab.cn)")
    parser.add_option("-t", "--tag", dest="tag", default="", help="æ–‡ç« çš„ TAG æ ‡ç­¾, å¤šä¸ªæ ‡ç­¾ç”¨åˆ†å·åˆ†éš” (é»˜è®¤: '')")
    parser.add_option("-o", "--out", dest="out", action="store_true", default=False, help="ä¿å­˜ä¸º md æ–‡æ¡£ (é»˜è®¤: create_at-slug.md) ")

    opts, args = parser.parse_args()
    if not opts.url:
        parser.error('æç¤ºï¼šURL ä¸èƒ½ä¸ºç©ºï¼')

    url  = opts.url.strip()
    site = opts.site.strip()
    tag  = opts.tag.strip()
    out  = opts.out

    headers = {
        "Content-Type": "application/json",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36"
    }
    resp = requests.request("GET", url, headers=headers)
    html = resp.text
    bs   = BeautifulSoup(html,"lxml")

    slug      = url.strip().split("/")[-2] if url.endswith("/") else url.strip().split("/")[-1]
    title     = bs.title.string.strip(' Â· è¯­é›€$')
    create_at = bs.find("meta", {"name":"weibo:article:create_at"}).attrs['content']
    update_at = bs.find("meta", {"name":"weibo:article:update_at"}).attrs['content']
    create    = create_at.split()[0]
    update    = update_at.split()[0]
    outfile   = create_at.split()[0] + "-" + slug + ".md"
    tags_list = []
    for t in tag.strip().split(";"):
        t = t.strip()
        if t:
            tags_list.append(t)
    tags = '[\"%s\"]' % ('\",\"'.join(tags_list))

    post_meata = "---\ntitle: '%s'\nslug: '%s'\ndate: '%s'\nlastmod: '%s'\ntype: posts\npublished: true\nauthor: æ²ˆç»´ç‡•\ntags: %s\n---\n\n" % (title, slug, create, update, tags)
    post_meata = post_meata + "> ğŸ“¢æœ¬ æ–‡ç« åŒæ­¥è‡ªä½œè€…çš„[è¯­é›€çŸ¥è¯†åº“](https://www.yuque.com/shenweiyan/)ï¼Œè¯·ç‚¹å‡»[è¿™é‡Œ](%s)é˜…è¯»åŸæ–‡ã€‚\n\n" % url

    md_url = url.strip("/")+'/markdown?plain=true&linebreak=false&anchor=false'
    md_res = requests.request("GET", md_url, headers=headers)
    body   = md_res.text
    #body = re.sub("<a name=\".*\"></a>","", body)  # æ­£åˆ™å»é™¤è¯­é›€å¯¼å‡ºçš„<a>æ ‡ç­¾
    #body = re.sub("\x00", "", body) # å»é™¤ä¸å¯è§å­—ç¬¦\x00
    #body = re.sub("\x05", "", body) # å»é™¤ä¸å¯è§å­—ç¬¦\x05
    body = re.sub(r'\<br \/\>!\[image.png\]',"\n![image.png]",body) # æ­£åˆ™å»é™¤è¯­é›€å¯¼å‡ºçš„å›¾ç‰‡åç´§è·Ÿçš„<br \>æ ‡ç­¾
    body = re.sub(r'\)\<br \/\>', ")\n", body)  # æ­£åˆ™å»é™¤è¯­é›€å¯¼å‡ºçš„å›¾ç‰‡åç´§è·Ÿçš„<br \>æ ‡ç­¾
    #pattern = r"!\[(?P<img_name>.*?)\]" \
    #          r"\((?P<img_src>https:\/\/cdn\.nlark\.com\/(?P<img_pre>yuque.*\/(?P<slug>\d+))\/(?P<filename>.*?\.[a-zA-z]+)).*\)"
    pattern  = r"!\[(?P<img_name>.*?)\]" \
               r"\((?P<yuque_imgurl>(?P<cdn_lark>https://cdn\.nlark\.com)/(?P<img_pre>yuque/[0-9]*/\d+/[\w]*/\d+)/(?P<filename>[\w-]*\.[a-zA-Z]*))[^!]*\)"
    repl     = r"![\g<img_name>](https://%s/\g<img_pre>/\g<filename>)" % site
    new_body = re.sub(pattern, repl, body)

    if out:
        with open(outfile, "w") as md:
            md.write(post_meata+new_body)
        print("âˆš ç»“æœå·²ä¿å­˜ä¸º: %s\nâˆš ç»“æœä¿å­˜æˆåŠŸï¼" % outfile)
    else:
        print(post_meata)
        print(new_body)


if __name__ == "__main__":
    __main__()
